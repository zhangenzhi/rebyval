experiment:
  context:
    name: cifar10-mlp-da
    multi-p: False

  main_loop:
    warmup: 
      student_nums: 1
      supervisor_trains: 0
    nums: 0
    student_nums: 0

  student:
    dataloader:
      name: cifar100 # default cifar10
      batch_size: 1024
      epochs: 300
    model:
      name: dnn # default dnn
      units: [512,256,128,128,100] # default 128,64,64,32
      activations: [relu,relu,relu,relu,softmax] # default relu
    loss:
      name: CategoricalCrossentropy
    metrics: 
      name: categorical_accuracy
    optimizer:
      name: sgd # default SGD
      learning_rate: 0.1 # default 0.01
    train_loop:
        valid:
          weight_space:
            format: sum_reduce
          valid_gap: 100000

  supervisor:
    dataloader:
      name: dnn_sumreduce
      replay_window: 1000
      batch_size: 128
      epochs: 200
    model:
      name: dnn # default dnn
      units: [128,64,32,1] # default 128,64,64,32
      activations: [relu,relu,relu,softplus] # default relu
    optimizer:
      name: sgd
      learning_rate: 0.01
    loss:
      name: MeanAbsoluteError #MeanAbsoluteError 
    train_loop:
        valid:
          valid_gap: 100 